## 파이프라인 구성 전략: Slurm Job Chaining ##
대규모 실험에서는 이전 단계가 성공적으로 끝나야 다음 단계가 시작되어야 한다. Slurm Slinky를 통해 쿠버네티스 자원을 점유하면서도 고전적인 HPC의 정교한 파이프라인 제어 방식을 적용한다.

#### 1. 작업 의존성(Dependency) 관리 ####
* Sequential Workflow: 데이터 전처리(CPU/AMX) → 모델 학습(GPU) → 체크포인트 검증 및 평가 순으로 이어지는 단계를 구성
* 의존성 옵션 활용: Slurm의 --dependency 옵션을 사용하여 앞선 작업이 정상 종료(afterok)되었을 때만 다음 작업이 큐에서 활성화되도록 설정.
```
sbatch --dependency=afterok:<JobID> train.sh
```

#### 2. 이기종 자원 파이프라인 최적화 ####
* 파티션 스위칭: 전처리 단계는 AMX 전용 파티션(amx-partition)에서 수행하고, 학습 단계는 GPU 전용 파티션(gpu-partition)으로 자동 전달되는 파이프라인을 구축하여 고가의 GPU 자원 대기 시간을 최소화.
* 자원 선점 및 해제: 작업이 종료되는 즉시 쿠버네티스 파드가 반납되도록 구성하여 클라우드 비용을 최적화

#### 3. 자동화된 재시작 및 에러 핸들링 ####
* 에러 트래핑: 파이프라인 중간에 작업이 실패할 경우, 관리자에게 알림을 보내거나 특정 체크포인트 지점부터 자동으로 작업을 재시작하는 Self-healing 파이프라인 구성.
* 로그 통합 관리: 각 단계에서 생성되는 로그를 Amazon CloudWatch 또는 중앙 집중형 로그 시스템(Lokii) 으로 수집하여 전체 파이프라인의 상태를 한눈에 모니터링.

#### 4. CI/CD 및 Argo Workflows 연동 ####
코드 변경 시 Argo Workflows가 트리거되어 Slurm에 작업을 제출하고, 완료 후 결과를 대시보드에 반영하는 최신 MLOps 아키텍처 구현.
